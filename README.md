# üí≥ Detecci√≥n de Fraude de transacciones bancarias

üë• **Integrantes:**
- Ariel Vargas  
- Domenica Bola√±os  

<div align="justify">

## üè¶ Introducci√≥n

Los fraudes en transacciones bancarias constituyen un delito financiero significativo y creciente, especialmente en la era de la banca digital. Se definen como un conjunto de estafas y actividades il√≠citas cuyo objetivo principal es obtener fondos, informaci√≥n confidencial, o acceso no autorizado a las cuentas de clientes e instituciones financieras. Estos actos provocan grandes p√©rdidas econ√≥micas tanto a individuos como a empresas a nivel global.

## üìä Dataset

Se utiliz√≥ un dataset de Kaggle Credit Card Fraud Detection, donde se tiene las siguientes variables:
- **Time**: N√∫meros de segundos entre realizaci√≥n de la transacci√≥n  
- **V1 - V28**: Caracter√≠sticas de las transacciones con transformadas en PCA  
- **Amount**: Cantidad realizada en la transacci√≥n  
- **Class**: Determina si la transacci√≥n es fraude o Leg√≠tima (0: Leg√≠tima, 1: Fraude)

<div align="center">
<img src="./Visualizaci√≥n/pairplot.png" width="600"/>
</div>

## üéØ Objetivo

Realizar un modelo de Machine Learning para detectar si las pr√≥ximas transacciones ser√≠an fraudes o leg√≠timas.

## ‚öôÔ∏è Descripci√≥n del Problema

### üßπ Preprocesamiento

Se realiz√≥ un an√°lisis del dataset para verificar su informaci√≥n, tipo de datos, etc. Adem√°s, se evidenci√≥ una **severa desproporci√≥n** en la visualizaci√≥n del desbalance de clase entre transacciones fraudulentas y leg√≠timas (aproximadamente **0.17%** de fraude).

Para manejar este problema de desbalance y evitar que el modelo ignore la clase minoritaria:
1. Se utiliz√≥ el ajuste de **peso de clase** intr√≠nseco de XGBoost mediante el par√°metro **`scale_pos_weight`**. Este par√°metro se establece con la raz√≥n del n√∫mero de ejemplos negativos sobre el n√∫mero de ejemplos positivos, dirigiendo el enfoque del modelo a la detecci√≥n de fraude.

<div align="center">
<img src="./Visualizaci√≥n/Transacciones%20Fraudulentas.png" width="600"/>
<img src="./Visualizaci√≥n/Desbalance%20de%20clases.png" width="600"/>
</div>

### üß† Entrenamiento y Optimizaci√≥n

Para lograr un modelo robusto, se utiliz√≥ el algoritmo **XGBoost Classifier**. Se realiz√≥ un **ajuste de hiperpar√°metros (HPO)** utilizando la librer√≠a **Optuna** para encontrar la configuraci√≥n √≥ptima, bas√°ndose en la m√©trica **AUC-ROC** debido a que nos permite clasificar el modelo si es fraude o leg√≠tima. El modelo fue entrenado con la estrategia de peso de clase, de esa manera manejamos el desbalance de clase utilizando la raz√≥n entre los n√∫meros de ejemplos entre las transacciones leg√≠timas y el n√∫mero de peso entre las transacciones fraudulentas.

Luego del entrenamiento, se implement√≥ la librer√≠a **SHAP (SHapley Additive exPlanations)** para generar gr√°ficos de explicabilidad y justificar las decisiones del modelo.

Se revis√≥ la **curva de calibraci√≥n** inicial. Dado que no estaba cerca de la l√≠nea de perfecta calibraci√≥n, se realiz√≥ un proceso de **calibraci√≥n del modelo** utilizando estrategias basadas en cuantiles para mejorar la correspondencia entre las probabilidades predichas y las observadas. **Las m√©tricas de desempe√±o y la evaluaci√≥n final se basan en este modelo calibrado.**

<div align="center">
<img src="./Visualizaci√≥n/Curva%20de%20calibracion.png" width="600"/>
</div>

## üìà An√°lisis y Resultados

1.  El an√°lisis de Detecci√≥n se centra en la capacidad de detecci√≥n. La **Matriz de Confusi√≥n** demuestra que el modelo optimizado logra un alto valor de **Recall (Exhaustividad)**. El modelo optimizado originalmente por Optuna (XGBoost) mostr√≥ un Recall de 0.83 con una Precisi√≥n de 0.70. Sin embargo, tras el proceso de calibraci√≥n para mejorar la fiabilidad de las probabilidades, los valores finales son:
    * **Recall del Modelo Calibrado:** **0.74**
    * **Precisi√≥n del Modelo Calibrado:** **0.83**
    
<div align="center">
<img src="./Visualizaci√≥n/Matriz%20confusion%20modelo%20optimizado.png" width="500"/>
<img src="./Visualizaci√≥n/Matriz%20confusion%20modelo%20calibrado.png" width="500"/>
</div>
      
2.  La optimizaci√≥n con Optuna y el proceso de calibraci√≥n resultaron en un **ROC-AUC de 0.9715**. Este valor, muy cercano a 1.0, indica que el modelo tiene una excepcional capacidad para discriminar entre las clases.

<div align="center">
<img src="./Visualizaci√≥n/Curva%20ROC.png" width="600"/>
</div>

3.  Este an√°lisis confirma el equilibrio entre detecci√≥n y fiabilidad. El valor del **√Årea Bajo la Curva de Precisi√≥n-Recall (PR-AUC)** es de **0.8540**. Este valor valida que el modelo mantiene una **buena Precisi√≥n** (0.83) incluso cuando se maximiza la detecci√≥n de fraude (alto Recall de 0.74).

<div align="center">
<img src="./Visualizaci√≥n/Curva%20Presicion%20Recall.png" width="600"/>
</div>

4.  La implementaci√≥n de **SHAP** provee transparencia al modelo. El **Summary Plot** y el **Bar Plot** confirman que las caracter√≠sticas **V14**, **V4**, y **V3** son las m√°s influyentes. El **Dependence Plot** demuestra, por ejemplo, que valores **muy negativos** en la caracter√≠stica **V14** tienen el **mayor impacto positivo** en la predicci√≥n de fraude, justificando las clasificaciones del modelo.

<div align="center">
<img src="./Visualizaci√≥n/Summary%20plot.png" width="600"/>
</div>

## üßæ Conclusi√≥n

El objetivo de crear un modelo de Machine Learning para detectar transacciones fraudulentas se cumpli√≥ con √©xito utilizando un enfoque avanzado de **XGBoost optimizado por Optuna** y calibrado.

El modelo logr√≥ un equilibrio s√≥lido entre detectar la mayor cantidad de fraudes posibles (alto **Recall** de **0.74**) y evitar la generaci√≥n excesiva de alertas falsas (alta **Precisi√≥n** de **0.83**). La evidencia de la **Matriz de Confusi√≥n** y la m√©trica **PR-AUC** (0.8540) confirma que la soluci√≥n es robusta contra el severo desbalance de clases, proporcionando una herramienta valiosa para la mitigaci√≥n de riesgos en transacciones bancarias.

Es fundamental destacar que la Exactitud (Accuracy) no es una m√©trica v√°lida para evaluar este proyecto, ya que el dataset est√° severamente desbalanceado. Un alto valor de Accuracy ser√≠a enga√±oso y no reflejar√≠a la verdadera capacidad del modelo para detectar fraudes. Por esta raz√≥n, la evaluaci√≥n se centr√≥ en las m√©tricas de rendimiento para la clase minoritaria.

---

## üìÇ Estructura del Proyecto y Entorno

La estructura de carpetas se organiza para seguir el flujo de trabajo del cient√≠fico de datos, desde el modelado hasta la generaci√≥n de outputs explicativos:

/ (Ra√≠z del Proyecto)  
      ‚îÇ  
      ‚îú‚îÄ‚îÄ README.md                 # Documentaci√≥n general del proyecto  
      ‚îú‚îÄ‚îÄ Proyecto_CIAP.ipynb       # Notebook principal con an√°lisis y modelado  
      ‚îÇ  
      ‚îú‚îÄ‚îÄ /Entrenamiento/           # Archivos y scripts del proceso de Machine Learning  
      ‚îÇ  
      ‚îú‚îÄ‚îÄ /Implementaci√≥n/          # C√≥digo para pruebas con nuevos datos (uso del modelo)  
      ‚îÇ  
      ‚îî‚îÄ‚îÄ /Visualizaci√≥n/           # Resultados gr√°ficos (curvas ROC/PR, SHAP, etc.)
   

### üíª Versi√≥n de Python y Librer√≠as Clave
El proyecto fue desarrollado y ejecutado en un entorno de Google Colab.

**Python Versi√≥n:** Python 3.10+ (Est√°ndar en Google Colab)

**Librer√≠as Clave (Utilizadas para las m√©tricas y optimizaci√≥n):**
- **xgboost** y **optuna**: Para el modelado y la optimizaci√≥n de hiperpar√°metros.  
- **shap**: Para la explicabilidad de las decisiones del modelo.  
- **sklearn**: Para el preprocesamiento y el c√°lculo de m√©tricas esenciales.  
- **matplotlib**, **seaborn**: Para la visualizaci√≥n de resultados.

</div>

